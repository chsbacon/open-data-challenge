{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th># Clients</th>\n",
       "      <th>weekday-0</th>\n",
       "      <th>weekday-1</th>\n",
       "      <th>weekday-2</th>\n",
       "      <th>weekday-3</th>\n",
       "      <th>weekday-4</th>\n",
       "      <th>weekday-5</th>\n",
       "      <th>weekday-6</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.820006</td>\n",
       "      <td>-0.792066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0.579624</td>\n",
       "      <td>-1.667506</td>\n",
       "      <td>-0.792066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1.589692</td>\n",
       "      <td>-1.067194</td>\n",
       "      <td>-0.792066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.725840</td>\n",
       "      <td>-1.262831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-2.138339</td>\n",
       "      <td>-1.427599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-0.218454</td>\n",
       "      <td>-2.208964</td>\n",
       "      <td>-1.757135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>0.592094</td>\n",
       "      <td>-2.832818</td>\n",
       "      <td>-2.580974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>-0.318214</td>\n",
       "      <td>-2.997609</td>\n",
       "      <td>-2.828126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-2.950526</td>\n",
       "      <td>-2.710435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-2.020631</td>\n",
       "      <td>-2.322053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.855319</td>\n",
       "      <td>-1.062756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.054903</td>\n",
       "      <td>-0.333070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.337403</td>\n",
       "      <td>-0.709682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>-0.031405</td>\n",
       "      <td>-1.785214</td>\n",
       "      <td>-1.239293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>-0.255864</td>\n",
       "      <td>-1.832297</td>\n",
       "      <td>-1.098064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>-0.056344</td>\n",
       "      <td>-1.749902</td>\n",
       "      <td>-0.921527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>-0.106224</td>\n",
       "      <td>-0.820006</td>\n",
       "      <td>-0.874450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.490423</td>\n",
       "      <td>-0.662606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.020110</td>\n",
       "      <td>-0.803835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>-0.118694</td>\n",
       "      <td>-1.326152</td>\n",
       "      <td>-0.744990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>-0.131164</td>\n",
       "      <td>-1.220215</td>\n",
       "      <td>-0.438992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>0.467394</td>\n",
       "      <td>-1.161360</td>\n",
       "      <td>-0.333070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>5.056343</td>\n",
       "      <td>-1.302610</td>\n",
       "      <td>-1.074525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.820006</td>\n",
       "      <td>-1.121602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.090215</td>\n",
       "      <td>-0.450761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.349173</td>\n",
       "      <td>-0.827373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.561568</td>\n",
       "      <td>-1.321677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.349694</td>\n",
       "      <td>-1.415830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>-0.230924</td>\n",
       "      <td>-1.691048</td>\n",
       "      <td>-1.286370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.985318</td>\n",
       "      <td>-1.662982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.478652</td>\n",
       "      <td>-0.921527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.702298</td>\n",
       "      <td>-1.286370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.596881</td>\n",
       "      <td>-1.404061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.984798</td>\n",
       "      <td>-1.180447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.419798</td>\n",
       "      <td>-0.827373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.796465</td>\n",
       "      <td>-0.639067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.608132</td>\n",
       "      <td>-0.756759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.349173</td>\n",
       "      <td>-0.156533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.090215</td>\n",
       "      <td>-0.062380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.690527</td>\n",
       "      <td>-0.497838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.702298</td>\n",
       "      <td>-0.568453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2017-12-02</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-02</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.161360</td>\n",
       "      <td>-0.603760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.678757</td>\n",
       "      <td>-0.933296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.937715</td>\n",
       "      <td>-0.591991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>0.355165</td>\n",
       "      <td>-0.513965</td>\n",
       "      <td>-0.650836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.855319</td>\n",
       "      <td>-0.756759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.337923</td>\n",
       "      <td>-0.945065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2017-12-08</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-08</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.820527</td>\n",
       "      <td>-1.356984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>0.317755</td>\n",
       "      <td>-2.385526</td>\n",
       "      <td>-1.439368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.891152</td>\n",
       "      <td>-1.568829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.290839</td>\n",
       "      <td>-1.192217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.361464</td>\n",
       "      <td>-1.921903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-2.197193</td>\n",
       "      <td>-2.145516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.549798</td>\n",
       "      <td>-1.557060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-2.303131</td>\n",
       "      <td>-1.674751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.279069</td>\n",
       "      <td>-1.415830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-1.231985</td>\n",
       "      <td>-0.686144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.561048</td>\n",
       "      <td>-0.674375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.408028</td>\n",
       "      <td>-0.121225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>-0.584590</td>\n",
       "      <td>-0.639067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time  # Clients  weekday-0  weekday-1  weekday-2  weekday-3  \\\n",
       "0    2017-01-01         93          0          0          0          0   \n",
       "1    2017-01-02         73          1          0          0          0   \n",
       "2    2017-01-03         87          0          1          0          0   \n",
       "3    2017-01-04         97          0          0          1          0   \n",
       "4    2017-01-05         92          0          0          0          1   \n",
       "5    2017-01-06         88          0          0          0          0   \n",
       "6    2017-01-07         39          0          0          0          0   \n",
       "7    2017-01-08         40          0          0          0          0   \n",
       "8    2017-01-09         74          1          0          0          0   \n",
       "9    2017-01-10         67          0          1          0          0   \n",
       "10   2017-01-11         88          0          0          1          0   \n",
       "11   2017-01-12        105          0          0          0          1   \n",
       "12   2017-01-13        150          0          0          0          0   \n",
       "13   2017-01-14         94          0          0          0          0   \n",
       "14   2017-01-15         74          0          0          0          0   \n",
       "15   2017-01-16         95          1          0          0          0   \n",
       "16   2017-01-17         83          0          1          0          0   \n",
       "17   2017-01-18        108          0          0          1          0   \n",
       "18   2017-01-19        104          0          0          0          1   \n",
       "19   2017-01-20        109          0          0          0          0   \n",
       "20   2017-01-21        122          0          0          0          0   \n",
       "21   2017-01-22         69          0          0          0          0   \n",
       "22   2017-01-23         55          1          0          0          0   \n",
       "23   2017-01-24         96          0          1          0          0   \n",
       "24   2017-01-25        135          0          0          1          0   \n",
       "25   2017-01-26        119          0          0          0          1   \n",
       "26   2017-01-27         97          0          0          0          0   \n",
       "27   2017-01-28         88          0          0          0          0   \n",
       "28   2017-01-29         61          0          0          0          0   \n",
       "29   2017-01-30         61          1          0          0          0   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "323  2017-11-21         41          0          1          0          0   \n",
       "324  2017-11-22         25          0          0          1          0   \n",
       "325  2017-11-23          5          0          0          0          1   \n",
       "326  2017-11-24         30          0          0          0          0   \n",
       "327  2017-11-25         48          0          0          0          0   \n",
       "328  2017-11-26         26          0          0          0          0   \n",
       "329  2017-11-27         50          1          0          0          0   \n",
       "330  2017-11-28         53          0          1          0          0   \n",
       "331  2017-11-29         75          0          0          1          0   \n",
       "332  2017-11-30         81          0          0          0          1   \n",
       "333  2017-12-01        159          0          0          0          0   \n",
       "334  2017-12-02         71          0          0          0          0   \n",
       "335  2017-12-03         64          0          0          0          0   \n",
       "336  2017-12-04         68          1          0          0          0   \n",
       "337  2017-12-05         72          0          1          0          0   \n",
       "338  2017-12-06         66          0          0          1          0   \n",
       "339  2017-12-07         76          0          0          0          1   \n",
       "340  2017-12-08         76          0          0          0          0   \n",
       "341  2017-12-09         60          0          0          0          0   \n",
       "342  2017-12-10         46          0          0          0          0   \n",
       "343  2017-12-11         61          1          0          0          0   \n",
       "344  2017-12-12         53          0          1          0          0   \n",
       "345  2017-12-13         61          0          0          1          0   \n",
       "346  2017-12-14         59          0          0          0          1   \n",
       "347  2017-12-15         57          0          0          0          0   \n",
       "348  2017-12-16         76          0          0          0          0   \n",
       "349  2017-12-17         44          0          0          0          0   \n",
       "350  2017-12-18         59          1          0          0          0   \n",
       "351  2017-12-19         87          0          1          0          0   \n",
       "352  2017-12-20        106          0          0          1          0   \n",
       "\n",
       "     weekday-4  weekday-5  weekday-6        DATE      PRCP      TMAX      TMIN  \n",
       "0            0          0          1  2017-01-01 -0.343154 -0.820006 -0.792066  \n",
       "1            0          0          0  2017-01-02  0.579624 -1.667506 -0.792066  \n",
       "2            0          0          0  2017-01-03  1.589692 -1.067194 -0.792066  \n",
       "3            0          0          0  2017-01-04 -0.343154 -0.725840 -1.262831  \n",
       "4            0          0          0  2017-01-05 -0.343154 -2.138339 -1.427599  \n",
       "5            1          0          0  2017-01-06 -0.218454 -2.208964 -1.757135  \n",
       "6            0          1          0  2017-01-07  0.592094 -2.832818 -2.580974  \n",
       "7            0          0          1  2017-01-08 -0.318214 -2.997609 -2.828126  \n",
       "8            0          0          0  2017-01-09 -0.343154 -2.950526 -2.710435  \n",
       "9            0          0          0  2017-01-10 -0.343154 -2.020631 -2.322053  \n",
       "10           0          0          0  2017-01-11 -0.343154 -0.855319 -1.062756  \n",
       "11           0          0          0  2017-01-12 -0.343154 -0.054903 -0.333070  \n",
       "12           1          0          0  2017-01-13 -0.343154 -0.337403 -0.709682  \n",
       "13           0          1          0  2017-01-14 -0.031405 -1.785214 -1.239293  \n",
       "14           0          0          1  2017-01-15 -0.255864 -1.832297 -1.098064  \n",
       "15           0          0          0  2017-01-16 -0.056344 -1.749902 -0.921527  \n",
       "16           0          0          0  2017-01-17 -0.106224 -0.820006 -0.874450  \n",
       "17           0          0          0  2017-01-18 -0.343154 -0.490423 -0.662606  \n",
       "18           0          0          0  2017-01-19 -0.343154 -1.020110 -0.803835  \n",
       "19           1          0          0  2017-01-20 -0.118694 -1.326152 -0.744990  \n",
       "20           0          1          0  2017-01-21 -0.131164 -1.220215 -0.438992  \n",
       "21           0          0          1  2017-01-22  0.467394 -1.161360 -0.333070  \n",
       "22           0          0          0  2017-01-23  5.056343 -1.302610 -1.074525  \n",
       "23           0          0          0  2017-01-24 -0.343154 -0.820006 -1.121602  \n",
       "24           0          0          0  2017-01-25 -0.343154 -0.090215 -0.450761  \n",
       "25           0          0          0  2017-01-26 -0.343154 -0.349173 -0.827373  \n",
       "26           1          0          0  2017-01-27 -0.343154 -1.561568 -1.321677  \n",
       "27           0          1          0  2017-01-28 -0.343154 -1.349694 -1.415830  \n",
       "28           0          0          1  2017-01-29 -0.230924 -1.691048 -1.286370  \n",
       "29           0          0          0  2017-01-30 -0.343154 -1.985318 -1.662982  \n",
       "..         ...        ...        ...         ...       ...       ...       ...  \n",
       "323          0          0          0  2017-11-21 -0.343154 -0.478652 -0.921527  \n",
       "324          0          0          0  2017-11-22 -0.343154 -0.702298 -1.286370  \n",
       "325          0          0          0  2017-11-23 -0.343154 -1.596881 -1.404061  \n",
       "326          1          0          0  2017-11-24 -0.343154 -0.984798 -1.180447  \n",
       "327          0          1          0  2017-11-25 -0.343154 -0.419798 -0.827373  \n",
       "328          0          0          1  2017-11-26 -0.343154 -0.796465 -0.639067  \n",
       "329          0          0          0  2017-11-27 -0.343154 -0.608132 -0.756759  \n",
       "330          0          0          0  2017-11-28 -0.343154 -0.349173 -0.156533  \n",
       "331          0          0          0  2017-11-29 -0.343154 -0.090215 -0.062380  \n",
       "332          0          0          0  2017-11-30 -0.343154 -0.690527 -0.497838  \n",
       "333          1          0          0  2017-12-01 -0.343154 -0.702298 -0.568453  \n",
       "334          0          1          0  2017-12-02 -0.343154 -1.161360 -0.603760  \n",
       "335          0          0          1  2017-12-03 -0.343154 -0.678757 -0.933296  \n",
       "336          0          0          0  2017-12-04 -0.343154 -0.937715 -0.591991  \n",
       "337          0          0          0  2017-12-05  0.355165 -0.513965 -0.650836  \n",
       "338          0          0          0  2017-12-06 -0.343154 -0.855319 -0.756759  \n",
       "339          0          0          0  2017-12-07 -0.343154 -1.337923 -0.945065  \n",
       "340          1          0          0  2017-12-08 -0.343154 -1.820527 -1.356984  \n",
       "341          0          1          0  2017-12-09  0.317755 -2.385526 -1.439368  \n",
       "342          0          0          1  2017-12-10 -0.343154 -1.891152 -1.568829  \n",
       "343          0          0          0  2017-12-11 -0.343154 -1.290839 -1.192217  \n",
       "344          0          0          0  2017-12-12 -0.343154 -1.361464 -1.921903  \n",
       "345          0          0          0  2017-12-13 -0.343154 -2.197193 -2.145516  \n",
       "346          0          0          0  2017-12-14 -0.343154 -1.549798 -1.557060  \n",
       "347          1          0          0  2017-12-15 -0.343154 -2.303131 -1.674751  \n",
       "348          0          1          0  2017-12-16 -0.343154 -1.279069 -1.415830  \n",
       "349          0          0          1  2017-12-17 -0.343154 -1.231985 -0.686144  \n",
       "350          0          0          0  2017-12-18 -0.343154 -0.561048 -0.674375  \n",
       "351          0          0          0  2017-12-19 -0.343154 -0.408028 -0.121225  \n",
       "352          0          0          0  2017-12-20 -0.343154 -0.584590 -0.639067  \n",
       "\n",
       "[353 rows x 13 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_path = os.path.join('..','data','weather','precip_temp.csv')\n",
    "weather_df = pd.read_csv(weather_path)\n",
    "clients_path = os.path.join('..','data','wifi','**','Clients per day.csv')\n",
    "clients_df = pd.concat(map(lambda csv: pd.read_csv(csv, parse_dates=[0]),\n",
    "                           glob.glob(clients_path)), ignore_index=True)\n",
    "weekday_labels = []\n",
    "for d in range(7):\n",
    "    label = 'weekday-%i' % d\n",
    "    weekday_labels.append(label)\n",
    "    clients_df[label] = [int(dt.weekday()==d) for dt in clients_df['Time']]\n",
    "# Put clients date in the same format as it is in the weather data\n",
    "clients_df['Time'] = [dt.strftime('%Y-%m-%d') for dt in clients_df['Time']]\n",
    "\n",
    "# This merge ignores the missing data point in the weather data\n",
    "all_data = clients_df.merge(weather_df, left_on='Time', right_on='DATE')\n",
    "\n",
    "cols_to_norm = ['TMIN', 'TMAX', 'PRCP']\n",
    "for col in cols_to_norm:\n",
    "    all_data[col] = zscore(all_data[col])\n",
    "\n",
    "x_labels = weekday_labels + ['PRCP', 'TMAX', 'TMIN']\n",
    "day_x=all_data[weekday_labels].values\n",
    "weather_x=all_data[['PRCP', 'TMAX', 'TMIN']].values\n",
    "date_x=np.expand_dims(np.arange(0,353/365,1/365).astype('float32'),axis=1)\n",
    "y_labels = ['# Clients']\n",
    "x = all_data[x_labels].values\n",
    "y = all_data[y_labels].values\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_607/Relu:0\", shape=(?, 4), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_88 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_89 (InputLayer)           (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_604 (Dense)               (None, 10)           40          input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_608 (Dense)               (None, 10)           80          input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_448 (Dropout)           (None, 10)           0           dense_604[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_451 (Dropout)           (None, 10)           0           dense_608[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_605 (Dense)               (None, 10)           110         dropout_448[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_609 (Dense)               (None, 10)           110         dropout_451[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_449 (Dropout)           (None, 10)           0           dense_605[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_452 (Dropout)           (None, 10)           0           dense_609[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_606 (Dense)               (None, 5)            55          dropout_449[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_610 (Dense)               (None, 10)           110         dropout_452[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_450 (Dropout)           (None, 5)            0           dense_606[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_453 (Dropout)           (None, 10)           0           dense_610[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_607 (Dense)               (None, 4)            24          dropout_450[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_611 (Dense)               (None, 5)            55          dropout_453[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 9)            0           dense_607[0][0]                  \n",
      "                                                                 dense_611[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_616 (Dense)               (None, 10)           100         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_457 (Dropout)           (None, 10)           0           dense_616[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_617 (Dense)               (None, 10)           110         dropout_457[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_458 (Dropout)           (None, 10)           0           dense_617[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_618 (Dense)               (None, 10)           110         dropout_458[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_459 (Dropout)           (None, 10)           0           dense_618[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_619 (Dense)               (None, 1)            11          dropout_459[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 915\n",
      "Trainable params: 915\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 317 samples, validate on 36 samples\n",
      "Epoch 1/1000\n",
      "317/317 [==============================] - 4s 11ms/step - loss: 99.8976 - val_loss: 99.8774\n",
      "Epoch 2/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 99.8693 - val_loss: 99.8631\n",
      "Epoch 3/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 99.9480 - val_loss: 99.8497\n",
      "Epoch 4/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 99.8755 - val_loss: 99.8360\n",
      "Epoch 5/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 99.8956 - val_loss: 99.8213\n",
      "Epoch 6/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 99.8900 - val_loss: 99.8071\n",
      "Epoch 7/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 99.9297 - val_loss: 99.7933\n",
      "Epoch 8/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 99.8033 - val_loss: 99.7787\n",
      "Epoch 9/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 99.9470 - val_loss: 99.7663\n",
      "Epoch 10/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 99.6994 - val_loss: 99.7532\n",
      "Epoch 11/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 99.7964 - val_loss: 99.7393\n",
      "Epoch 12/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 99.8344 - val_loss: 99.7242\n",
      "Epoch 13/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 99.8032 - val_loss: 99.7083\n",
      "Epoch 14/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 99.7477 - val_loss: 99.6923\n",
      "Epoch 15/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 99.7702 - val_loss: 99.6772\n",
      "Epoch 16/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 99.7465 - val_loss: 99.6619\n",
      "Epoch 17/1000\n",
      "317/317 [==============================] - 0s 123us/step - loss: 99.8414 - val_loss: 99.6470\n",
      "Epoch 18/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 99.7190 - val_loss: 99.6318\n",
      "Epoch 19/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 99.6477 - val_loss: 99.6152\n",
      "Epoch 20/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 99.7010 - val_loss: 99.5979\n",
      "Epoch 21/1000\n",
      "317/317 [==============================] - 0s 111us/step - loss: 99.6884 - val_loss: 99.5816\n",
      "Epoch 22/1000\n",
      "317/317 [==============================] - 0s 109us/step - loss: 99.7827 - val_loss: 99.5649\n",
      "Epoch 23/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 99.6162 - val_loss: 99.5455\n",
      "Epoch 24/1000\n",
      "317/317 [==============================] - 0s 120us/step - loss: 99.6274 - val_loss: 99.5256\n",
      "Epoch 25/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 99.5353 - val_loss: 99.5040\n",
      "Epoch 26/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 99.6405 - val_loss: 99.4837\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 89us/step - loss: 99.5441 - val_loss: 99.4609\n",
      "Epoch 28/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 99.4541 - val_loss: 99.4383\n",
      "Epoch 29/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.6554 - val_loss: 99.4166\n",
      "Epoch 30/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.6920 - val_loss: 99.3959\n",
      "Epoch 31/1000\n",
      "317/317 [==============================] - 0s 87us/step - loss: 99.3795 - val_loss: 99.3719\n",
      "Epoch 32/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 99.4461 - val_loss: 99.3451\n",
      "Epoch 33/1000\n",
      "317/317 [==============================] - 0s 82us/step - loss: 99.5385 - val_loss: 99.3168\n",
      "Epoch 34/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.4209 - val_loss: 99.2907\n",
      "Epoch 35/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 99.5586 - val_loss: 99.2634\n",
      "Epoch 36/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 99.4216 - val_loss: 99.2368\n",
      "Epoch 37/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 99.4397 - val_loss: 99.2084\n",
      "Epoch 38/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.4088 - val_loss: 99.1803\n",
      "Epoch 39/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 99.3380 - val_loss: 99.1502\n",
      "Epoch 40/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.4265 - val_loss: 99.1200\n",
      "Epoch 41/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 99.4463 - val_loss: 99.0889\n",
      "Epoch 42/1000\n",
      "317/317 [==============================] - 0s 82us/step - loss: 99.2259 - val_loss: 99.0538\n",
      "Epoch 43/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 99.2156 - val_loss: 99.0144\n",
      "Epoch 44/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 99.3188 - val_loss: 98.9716\n",
      "Epoch 45/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 99.1830 - val_loss: 98.9271\n",
      "Epoch 46/1000\n",
      "317/317 [==============================] - 0s 82us/step - loss: 99.2689 - val_loss: 98.8866\n",
      "Epoch 47/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 99.2129 - val_loss: 98.8434\n",
      "Epoch 48/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 99.3264 - val_loss: 98.8022\n",
      "Epoch 49/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.0752 - val_loss: 98.7608\n",
      "Epoch 50/1000\n",
      "317/317 [==============================] - 0s 82us/step - loss: 99.2602 - val_loss: 98.7164\n",
      "Epoch 51/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 98.9025 - val_loss: 98.6671\n",
      "Epoch 52/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 99.2817 - val_loss: 98.6194\n",
      "Epoch 53/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 98.9874 - val_loss: 98.5689\n",
      "Epoch 54/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 99.0367 - val_loss: 98.5129\n",
      "Epoch 55/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 99.0021 - val_loss: 98.4518\n",
      "Epoch 56/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 99.0338 - val_loss: 98.3940\n",
      "Epoch 57/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 98.4312 - val_loss: 98.3234\n",
      "Epoch 58/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 98.8862 - val_loss: 98.2527\n",
      "Epoch 59/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 98.9764 - val_loss: 98.1878\n",
      "Epoch 60/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 98.5254 - val_loss: 98.1129\n",
      "Epoch 61/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 98.5737 - val_loss: 98.0322\n",
      "Epoch 62/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 98.4370 - val_loss: 97.9369\n",
      "Epoch 63/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 98.6883 - val_loss: 97.8481\n",
      "Epoch 64/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 98.3923 - val_loss: 97.7675\n",
      "Epoch 65/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 98.3462 - val_loss: 97.6763\n",
      "Epoch 66/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 97.9218 - val_loss: 97.5693\n",
      "Epoch 67/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 98.3220 - val_loss: 97.4707\n",
      "Epoch 68/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 98.1901 - val_loss: 97.3631\n",
      "Epoch 69/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 98.3241 - val_loss: 97.2572\n",
      "Epoch 70/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 98.2774 - val_loss: 97.1564\n",
      "Epoch 71/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 97.8250 - val_loss: 97.0287\n",
      "Epoch 72/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 97.7104 - val_loss: 96.8994\n",
      "Epoch 73/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 98.3261 - val_loss: 96.7750\n",
      "Epoch 74/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 97.9070 - val_loss: 96.6462\n",
      "Epoch 75/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 97.9119 - val_loss: 96.5017\n",
      "Epoch 76/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 97.1306 - val_loss: 96.3368\n",
      "Epoch 77/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 97.2369 - val_loss: 96.1633\n",
      "Epoch 78/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 97.1285 - val_loss: 95.9885\n",
      "Epoch 79/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 96.2307 - val_loss: 95.7971\n",
      "Epoch 80/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 97.4547 - val_loss: 95.6282\n",
      "Epoch 81/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 96.9391 - val_loss: 95.4402\n",
      "Epoch 82/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 97.2607 - val_loss: 95.2389\n",
      "Epoch 83/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 96.7858 - val_loss: 95.0315\n",
      "Epoch 84/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 95.6894 - val_loss: 94.8310\n",
      "Epoch 85/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 95.8229 - val_loss: 94.6045\n",
      "Epoch 86/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 95.8570 - val_loss: 94.3730\n",
      "Epoch 87/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 95.4149 - val_loss: 94.1327\n",
      "Epoch 88/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 96.4946 - val_loss: 93.8935\n",
      "Epoch 89/1000\n",
      "317/317 [==============================] - 0s 111us/step - loss: 96.2570 - val_loss: 93.6566\n",
      "Epoch 90/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 95.4506 - val_loss: 93.3876\n",
      "Epoch 91/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 95.8374 - val_loss: 93.1362\n",
      "Epoch 92/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 95.1910 - val_loss: 92.8411\n",
      "Epoch 93/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 95.2457 - val_loss: 92.5169\n",
      "Epoch 94/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 95.2435 - val_loss: 92.1920\n",
      "Epoch 95/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 95.0817 - val_loss: 91.8708\n",
      "Epoch 96/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 94.3110 - val_loss: 91.5327\n",
      "Epoch 97/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 93.2002 - val_loss: 91.1519\n",
      "Epoch 98/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 93.8548 - val_loss: 90.7522\n",
      "Epoch 99/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 93.6712 - val_loss: 90.3680\n",
      "Epoch 100/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 93.3170 - val_loss: 89.9418\n",
      "Epoch 101/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 93.4754 - val_loss: 89.5354\n",
      "Epoch 102/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 93.4865 - val_loss: 89.1806\n",
      "Epoch 103/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 91.5776 - val_loss: 88.9700\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 95us/step - loss: 92.3607 - val_loss: 88.7387\n",
      "Epoch 105/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 93.0479 - val_loss: 88.5069\n",
      "Epoch 106/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 91.7254 - val_loss: 88.2583\n",
      "Epoch 107/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 92.2747 - val_loss: 88.0043\n",
      "Epoch 108/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 91.1652 - val_loss: 87.7725\n",
      "Epoch 109/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 91.6830 - val_loss: 87.5213\n",
      "Epoch 110/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 90.4156 - val_loss: 87.2614\n",
      "Epoch 111/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 90.7448 - val_loss: 86.9905\n",
      "Epoch 112/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 90.9125 - val_loss: 86.7318\n",
      "Epoch 113/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 90.5026 - val_loss: 86.4610\n",
      "Epoch 114/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 90.6599 - val_loss: 86.1743\n",
      "Epoch 115/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 88.8863 - val_loss: 85.8837\n",
      "Epoch 116/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 90.1691 - val_loss: 85.6081\n",
      "Epoch 117/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 90.5427 - val_loss: 85.2975\n",
      "Epoch 118/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 91.3305 - val_loss: 85.0540\n",
      "Epoch 119/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 88.7271 - val_loss: 84.7895\n",
      "Epoch 120/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 89.4951 - val_loss: 84.4824\n",
      "Epoch 121/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 88.6989 - val_loss: 84.1548\n",
      "Epoch 122/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 87.9980 - val_loss: 83.8399\n",
      "Epoch 123/1000\n",
      "317/317 [==============================] - 0s 85us/step - loss: 85.2480 - val_loss: 83.4909\n",
      "Epoch 124/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 86.9145 - val_loss: 83.0527\n",
      "Epoch 125/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 86.4818 - val_loss: 82.6232\n",
      "Epoch 126/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 86.1334 - val_loss: 82.2069\n",
      "Epoch 127/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 84.2110 - val_loss: 81.8451\n",
      "Epoch 128/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 83.3636 - val_loss: 81.4164\n",
      "Epoch 129/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 86.2549 - val_loss: 81.0197\n",
      "Epoch 130/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 85.9658 - val_loss: 80.6363\n",
      "Epoch 131/1000\n",
      "317/317 [==============================] - 0s 119us/step - loss: 84.0887 - val_loss: 80.3110\n",
      "Epoch 132/1000\n",
      "317/317 [==============================] - 0s 122us/step - loss: 84.4576 - val_loss: 79.9914\n",
      "Epoch 133/1000\n",
      "317/317 [==============================] - 0s 120us/step - loss: 85.0252 - val_loss: 79.7592\n",
      "Epoch 134/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 81.8613 - val_loss: 79.4817\n",
      "Epoch 135/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 84.6206 - val_loss: 79.2169\n",
      "Epoch 136/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 81.9543 - val_loss: 78.8355\n",
      "Epoch 137/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 82.1616 - val_loss: 78.4596\n",
      "Epoch 138/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 82.0944 - val_loss: 78.0623\n",
      "Epoch 139/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 82.5147 - val_loss: 77.7081\n",
      "Epoch 140/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 80.8194 - val_loss: 77.3696\n",
      "Epoch 141/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 80.6674 - val_loss: 76.9528\n",
      "Epoch 142/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 81.8744 - val_loss: 76.4791\n",
      "Epoch 143/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 82.5338 - val_loss: 76.0912\n",
      "Epoch 144/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 77.8452 - val_loss: 75.6365\n",
      "Epoch 145/1000\n",
      "317/317 [==============================] - 0s 82us/step - loss: 82.8837 - val_loss: 75.3368\n",
      "Epoch 146/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 79.9297 - val_loss: 75.0253\n",
      "Epoch 147/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 79.8070 - val_loss: 74.6939\n",
      "Epoch 148/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 82.1824 - val_loss: 74.3695\n",
      "Epoch 149/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 81.5844 - val_loss: 74.0683\n",
      "Epoch 150/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 83.9661 - val_loss: 73.8945\n",
      "Epoch 151/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 79.2777 - val_loss: 73.6554\n",
      "Epoch 152/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 77.2132 - val_loss: 73.2437\n",
      "Epoch 153/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 84.4457 - val_loss: 72.8580\n",
      "Epoch 154/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 79.3793 - val_loss: 72.4660\n",
      "Epoch 155/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 79.3783 - val_loss: 71.9958\n",
      "Epoch 156/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 78.8804 - val_loss: 71.6529\n",
      "Epoch 157/1000\n",
      "317/317 [==============================] - 0s 87us/step - loss: 80.4392 - val_loss: 71.3934\n",
      "Epoch 158/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 83.7829 - val_loss: 71.1999\n",
      "Epoch 159/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 80.8545 - val_loss: 71.0021\n",
      "Epoch 160/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 80.7296 - val_loss: 70.8632\n",
      "Epoch 161/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 79.3263 - val_loss: 70.6629\n",
      "Epoch 162/1000\n",
      "317/317 [==============================] - 0s 82us/step - loss: 80.9567 - val_loss: 70.4194\n",
      "Epoch 163/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 81.1359 - val_loss: 70.1546\n",
      "Epoch 164/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 78.1254 - val_loss: 69.8908\n",
      "Epoch 165/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 79.8195 - val_loss: 69.5592\n",
      "Epoch 166/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 79.7699 - val_loss: 69.3080\n",
      "Epoch 167/1000\n",
      "317/317 [==============================] - 0s 87us/step - loss: 82.9531 - val_loss: 69.1093\n",
      "Epoch 168/1000\n",
      "317/317 [==============================] - 0s 120us/step - loss: 80.8840 - val_loss: 68.9227\n",
      "Epoch 169/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 78.4431 - val_loss: 68.6213\n",
      "Epoch 170/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 80.0698 - val_loss: 68.4028\n",
      "Epoch 171/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 77.7414 - val_loss: 68.2856\n",
      "Epoch 172/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 78.3811 - val_loss: 68.1591\n",
      "Epoch 173/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 75.2296 - val_loss: 68.0001\n",
      "Epoch 174/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 79.2656 - val_loss: 67.8621\n",
      "Epoch 175/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 80.1456 - val_loss: 67.5455\n",
      "Epoch 176/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 74.6056 - val_loss: 67.2154\n",
      "Epoch 177/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 79.2817 - val_loss: 66.9892\n",
      "Epoch 178/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 80.8808 - val_loss: 66.7212\n",
      "Epoch 179/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 73.3102 - val_loss: 66.3539\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 98us/step - loss: 78.1716 - val_loss: 66.0360\n",
      "Epoch 181/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 76.2657 - val_loss: 65.7213\n",
      "Epoch 182/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 74.1403 - val_loss: 65.3004\n",
      "Epoch 183/1000\n",
      "317/317 [==============================] - 0s 87us/step - loss: 76.5658 - val_loss: 65.0570\n",
      "Epoch 184/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 75.8787 - val_loss: 65.0029\n",
      "Epoch 185/1000\n",
      "317/317 [==============================] - 0s 112us/step - loss: 75.5819 - val_loss: 64.8371\n",
      "Epoch 186/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 77.8483 - val_loss: 64.6398\n",
      "Epoch 187/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 79.1861 - val_loss: 64.4576\n",
      "Epoch 188/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 74.4326 - val_loss: 64.3041\n",
      "Epoch 189/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 74.8003 - val_loss: 64.1793\n",
      "Epoch 190/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 75.4318 - val_loss: 63.9748\n",
      "Epoch 191/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 77.7362 - val_loss: 63.8015\n",
      "Epoch 192/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 70.9820 - val_loss: 63.5839\n",
      "Epoch 193/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 77.2474 - val_loss: 63.4314\n",
      "Epoch 194/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 75.4557 - val_loss: 63.2791\n",
      "Epoch 195/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 79.4701 - val_loss: 63.2671\n",
      "Epoch 196/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 75.0846 - val_loss: 63.2672\n",
      "Epoch 197/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 76.8045 - val_loss: 63.2681\n",
      "Epoch 198/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 75.4155 - val_loss: 63.2465\n",
      "Epoch 199/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 79.7866 - val_loss: 63.2507\n",
      "Epoch 200/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 71.4139 - val_loss: 63.1643\n",
      "Epoch 201/1000\n",
      "317/317 [==============================] - 0s 106us/step - loss: 74.8702 - val_loss: 63.0503\n",
      "Epoch 202/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 75.2409 - val_loss: 62.9404\n",
      "Epoch 203/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.6585 - val_loss: 62.8271\n",
      "Epoch 204/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 73.5907 - val_loss: 62.7410\n",
      "Epoch 205/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 74.8783 - val_loss: 62.6820\n",
      "Epoch 206/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 74.0739 - val_loss: 62.6273\n",
      "Epoch 207/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 77.9690 - val_loss: 62.5708\n",
      "Epoch 208/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 73.7007 - val_loss: 62.5930\n",
      "Epoch 209/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.2769 - val_loss: 62.5129\n",
      "Epoch 210/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 72.0614 - val_loss: 62.3369\n",
      "Epoch 211/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 73.5616 - val_loss: 62.1850\n",
      "Epoch 212/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 73.9281 - val_loss: 62.0901\n",
      "Epoch 213/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 74.7570 - val_loss: 61.9232\n",
      "Epoch 214/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 79.0156 - val_loss: 61.9180\n",
      "Epoch 215/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 78.7076 - val_loss: 62.0327\n",
      "Epoch 216/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 76.2615 - val_loss: 62.0494\n",
      "Epoch 217/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 73.2139 - val_loss: 61.9895\n",
      "Epoch 218/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.1157 - val_loss: 61.9005\n",
      "Epoch 219/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 75.4807 - val_loss: 61.8744\n",
      "Epoch 220/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 74.2752 - val_loss: 61.8117\n",
      "Epoch 221/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 72.9449 - val_loss: 61.7492\n",
      "Epoch 222/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 76.0466 - val_loss: 61.7091\n",
      "Epoch 223/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 75.4486 - val_loss: 61.6928\n",
      "Epoch 224/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 73.1448 - val_loss: 61.5907\n",
      "Epoch 225/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 72.5085 - val_loss: 61.4644\n",
      "Epoch 226/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 76.4473 - val_loss: 61.4402\n",
      "Epoch 227/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 73.5440 - val_loss: 61.4217\n",
      "Epoch 228/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 80.2190 - val_loss: 61.4408\n",
      "Epoch 229/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 70.6867 - val_loss: 61.4347\n",
      "Epoch 230/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 78.3163 - val_loss: 61.4757\n",
      "Epoch 231/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 75.5957 - val_loss: 61.4814\n",
      "Epoch 232/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 73.8866 - val_loss: 61.4571\n",
      "Epoch 233/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.5032 - val_loss: 61.3572\n",
      "Epoch 234/1000\n",
      "317/317 [==============================] - 0s 106us/step - loss: 69.8889 - val_loss: 61.2740\n",
      "Epoch 235/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 71.3645 - val_loss: 61.2063\n",
      "Epoch 236/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 76.8096 - val_loss: 61.1355\n",
      "Epoch 237/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 74.1139 - val_loss: 61.0719\n",
      "Epoch 238/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 68.6720 - val_loss: 60.9907\n",
      "Epoch 239/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 75.6772 - val_loss: 60.9136\n",
      "Epoch 240/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 77.4596 - val_loss: 60.8679\n",
      "Epoch 241/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 70.3656 - val_loss: 60.8084\n",
      "Epoch 242/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 71.8893 - val_loss: 60.8013\n",
      "Epoch 243/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 76.8132 - val_loss: 60.7826\n",
      "Epoch 244/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.4196 - val_loss: 60.7115\n",
      "Epoch 245/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.0565 - val_loss: 60.6646\n",
      "Epoch 246/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 80.4537 - val_loss: 60.6486\n",
      "Epoch 247/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 71.3610 - val_loss: 60.6849\n",
      "Epoch 248/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 71.0271 - val_loss: 60.6564\n",
      "Epoch 249/1000\n",
      "317/317 [==============================] - 0s 106us/step - loss: 71.1221 - val_loss: 60.6110\n",
      "Epoch 250/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 74.4090 - val_loss: 60.6023\n",
      "Epoch 251/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 72.6271 - val_loss: 60.5257\n",
      "Epoch 252/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 74.5427 - val_loss: 60.4604\n",
      "Epoch 253/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 74.0291 - val_loss: 60.3940\n",
      "Epoch 254/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 71.7907 - val_loss: 60.4280\n",
      "Epoch 255/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 72.6697 - val_loss: 60.3819\n",
      "Epoch 256/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 95us/step - loss: 73.9203 - val_loss: 60.3652\n",
      "Epoch 257/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 72.9327 - val_loss: 60.3349\n",
      "Epoch 258/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 73.2291 - val_loss: 60.2608\n",
      "Epoch 259/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 76.7350 - val_loss: 60.1840\n",
      "Epoch 260/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 72.9684 - val_loss: 60.1144\n",
      "Epoch 261/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 71.3704 - val_loss: 60.0252\n",
      "Epoch 262/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 74.3192 - val_loss: 59.9991\n",
      "Epoch 263/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 68.9895 - val_loss: 59.9611\n",
      "Epoch 264/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 70.1540 - val_loss: 59.8955\n",
      "Epoch 265/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 74.4303 - val_loss: 59.8282\n",
      "Epoch 266/1000\n",
      "317/317 [==============================] - 0s 106us/step - loss: 72.7285 - val_loss: 59.7577\n",
      "Epoch 267/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 73.8260 - val_loss: 59.7181\n",
      "Epoch 268/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 69.3842 - val_loss: 59.6569\n",
      "Epoch 269/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 73.9178 - val_loss: 59.5960\n",
      "Epoch 270/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.8436 - val_loss: 59.5275\n",
      "Epoch 271/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 69.4077 - val_loss: 59.4915\n",
      "Epoch 272/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 70.1904 - val_loss: 59.4626\n",
      "Epoch 273/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 68.7071 - val_loss: 59.4383\n",
      "Epoch 274/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 71.4944 - val_loss: 59.3943\n",
      "Epoch 275/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 76.5145 - val_loss: 59.3724\n",
      "Epoch 276/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 73.7577 - val_loss: 59.3942\n",
      "Epoch 277/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 74.0714 - val_loss: 59.4232\n",
      "Epoch 278/1000\n",
      "317/317 [==============================] - 0s 87us/step - loss: 71.2038 - val_loss: 59.4323\n",
      "Epoch 279/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 76.1684 - val_loss: 59.3935\n",
      "Epoch 280/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 79.5644 - val_loss: 59.3857\n",
      "Epoch 281/1000\n",
      "317/317 [==============================] - 0s 109us/step - loss: 70.4740 - val_loss: 59.3731\n",
      "Epoch 282/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 68.8694 - val_loss: 59.2982\n",
      "Epoch 283/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 69.0822 - val_loss: 59.2537\n",
      "Epoch 284/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 70.5580 - val_loss: 59.1649\n",
      "Epoch 285/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 70.9646 - val_loss: 59.1532\n",
      "Epoch 286/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 76.1967 - val_loss: 59.1695\n",
      "Epoch 287/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 71.4103 - val_loss: 59.1430\n",
      "Epoch 288/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 77.8937 - val_loss: 59.1370\n",
      "Epoch 289/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 70.2915 - val_loss: 59.1556\n",
      "Epoch 290/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.5471 - val_loss: 59.1097\n",
      "Epoch 291/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 72.0791 - val_loss: 59.0499\n",
      "Epoch 292/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 73.1150 - val_loss: 58.9790\n",
      "Epoch 293/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 69.8920 - val_loss: 58.9163\n",
      "Epoch 294/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 72.7093 - val_loss: 58.8933\n",
      "Epoch 295/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 70.0830 - val_loss: 58.8747\n",
      "Epoch 296/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.5779 - val_loss: 58.8570\n",
      "Epoch 297/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 68.9705 - val_loss: 58.8161\n",
      "Epoch 298/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.4968 - val_loss: 58.7278\n",
      "Epoch 299/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 69.6303 - val_loss: 58.6530\n",
      "Epoch 300/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 74.9306 - val_loss: 58.5914\n",
      "Epoch 301/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 71.1234 - val_loss: 58.5156\n",
      "Epoch 302/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 70.9493 - val_loss: 58.4537\n",
      "Epoch 303/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.8164 - val_loss: 58.4273\n",
      "Epoch 304/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.6236 - val_loss: 58.3391\n",
      "Epoch 305/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 69.9688 - val_loss: 58.2717\n",
      "Epoch 306/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 73.6643 - val_loss: 58.2386\n",
      "Epoch 307/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.1794 - val_loss: 58.2289\n",
      "Epoch 308/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.7513 - val_loss: 58.1900\n",
      "Epoch 309/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 71.4872 - val_loss: 58.1730\n",
      "Epoch 310/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 72.1470 - val_loss: 58.1425\n",
      "Epoch 311/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 69.2194 - val_loss: 58.1086\n",
      "Epoch 312/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 71.9165 - val_loss: 58.0811\n",
      "Epoch 313/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 76.5785 - val_loss: 58.0860\n",
      "Epoch 314/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 71.2923 - val_loss: 58.1575\n",
      "Epoch 315/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 73.6097 - val_loss: 58.1312\n",
      "Epoch 316/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.1137 - val_loss: 58.1049\n",
      "Epoch 317/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 71.4968 - val_loss: 58.0753\n",
      "Epoch 318/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 70.1430 - val_loss: 58.0632\n",
      "Epoch 319/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 70.0199 - val_loss: 58.0857\n",
      "Epoch 320/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.5707 - val_loss: 58.0784\n",
      "Epoch 321/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 69.1450 - val_loss: 58.0597\n",
      "Epoch 322/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 69.9251 - val_loss: 58.0084\n",
      "Epoch 323/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 65.6420 - val_loss: 57.9312\n",
      "Epoch 324/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.0716 - val_loss: 57.8917\n",
      "Epoch 325/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.2403 - val_loss: 57.8495\n",
      "Epoch 326/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 73.4894 - val_loss: 57.8456\n",
      "Epoch 327/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 64.7646 - val_loss: 57.8272\n",
      "Epoch 328/1000\n",
      "317/317 [==============================] - 0s 106us/step - loss: 71.0453 - val_loss: 57.8064\n",
      "Epoch 329/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 72.5790 - val_loss: 57.7800\n",
      "Epoch 330/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 68.6125 - val_loss: 57.7462\n",
      "Epoch 331/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 66.4245 - val_loss: 57.7070\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 108us/step - loss: 68.9065 - val_loss: 57.6593\n",
      "Epoch 333/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 71.2098 - val_loss: 57.6721\n",
      "Epoch 334/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 72.9065 - val_loss: 57.6937\n",
      "Epoch 335/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 69.4278 - val_loss: 57.6963\n",
      "Epoch 336/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.9935 - val_loss: 57.6297\n",
      "Epoch 337/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 73.7233 - val_loss: 57.5998\n",
      "Epoch 338/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 69.3254 - val_loss: 57.5194\n",
      "Epoch 339/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 72.1729 - val_loss: 57.4498\n",
      "Epoch 340/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 68.0901 - val_loss: 57.4019\n",
      "Epoch 341/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 68.7625 - val_loss: 57.2837\n",
      "Epoch 342/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.3033 - val_loss: 57.2010\n",
      "Epoch 343/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.6016 - val_loss: 57.1603\n",
      "Epoch 344/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 68.2847 - val_loss: 57.1185\n",
      "Epoch 345/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 73.3638 - val_loss: 57.0893\n",
      "Epoch 346/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 73.3323 - val_loss: 57.0738\n",
      "Epoch 347/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.0422 - val_loss: 57.0513\n",
      "Epoch 348/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 68.6726 - val_loss: 57.0089\n",
      "Epoch 349/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 64.6788 - val_loss: 56.9660\n",
      "Epoch 350/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.6907 - val_loss: 56.9330\n",
      "Epoch 351/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 66.0937 - val_loss: 56.9018\n",
      "Epoch 352/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 69.1757 - val_loss: 56.8320\n",
      "Epoch 353/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 71.8391 - val_loss: 56.7605\n",
      "Epoch 354/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.7782 - val_loss: 56.7689\n",
      "Epoch 355/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 69.3343 - val_loss: 56.8041\n",
      "Epoch 356/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 69.1244 - val_loss: 56.8164\n",
      "Epoch 357/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 66.9735 - val_loss: 56.8377\n",
      "Epoch 358/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 70.4255 - val_loss: 56.8558\n",
      "Epoch 359/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.0623 - val_loss: 56.7971\n",
      "Epoch 360/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 67.1460 - val_loss: 56.7255\n",
      "Epoch 361/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.7523 - val_loss: 56.7218\n",
      "Epoch 362/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4274 - val_loss: 56.7039\n",
      "Epoch 363/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.7709 - val_loss: 56.7116\n",
      "Epoch 364/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 67.8809 - val_loss: 56.6850\n",
      "Epoch 365/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.8654 - val_loss: 56.7046\n",
      "Epoch 366/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 70.7208 - val_loss: 56.7326\n",
      "Epoch 367/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.7029 - val_loss: 56.6949\n",
      "Epoch 368/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.3663 - val_loss: 56.7002\n",
      "Epoch 369/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 70.7079 - val_loss: 56.6727\n",
      "Epoch 370/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 68.0233 - val_loss: 56.6096\n",
      "Epoch 371/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.3037 - val_loss: 56.5425\n",
      "Epoch 372/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.9226 - val_loss: 56.5030\n",
      "Epoch 373/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 77.2636 - val_loss: 56.5279\n",
      "Epoch 374/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.0161 - val_loss: 56.5446\n",
      "Epoch 375/1000\n",
      "317/317 [==============================] - 0s 119us/step - loss: 70.8949 - val_loss: 56.5113\n",
      "Epoch 376/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 66.6784 - val_loss: 56.4855\n",
      "Epoch 377/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 69.0170 - val_loss: 56.4678\n",
      "Epoch 378/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 69.4737 - val_loss: 56.4867\n",
      "Epoch 379/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 67.5084 - val_loss: 56.4701\n",
      "Epoch 380/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 76.2970 - val_loss: 56.4629\n",
      "Epoch 381/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 77.6370 - val_loss: 56.4946\n",
      "Epoch 382/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 69.8041 - val_loss: 56.5514\n",
      "Epoch 383/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 63.5819 - val_loss: 56.4893\n",
      "Epoch 384/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 69.2081 - val_loss: 56.4240\n",
      "Epoch 385/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.4199 - val_loss: 56.4136\n",
      "Epoch 386/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.6412 - val_loss: 56.4220\n",
      "Epoch 387/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 71.0245 - val_loss: 56.4135\n",
      "Epoch 388/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.5069 - val_loss: 56.3811\n",
      "Epoch 389/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.9072 - val_loss: 56.3431\n",
      "Epoch 390/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 65.4881 - val_loss: 56.2903\n",
      "Epoch 391/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 69.1432 - val_loss: 56.2207\n",
      "Epoch 392/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 69.2789 - val_loss: 56.2064\n",
      "Epoch 393/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.9396 - val_loss: 56.2427\n",
      "Epoch 394/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 71.5632 - val_loss: 56.2516\n",
      "Epoch 395/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 70.2421 - val_loss: 56.2675\n",
      "Epoch 396/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.0597 - val_loss: 56.2518\n",
      "Epoch 397/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 68.6170 - val_loss: 56.2295\n",
      "Epoch 398/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 64.9581 - val_loss: 56.2000\n",
      "Epoch 399/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.5823 - val_loss: 56.1659\n",
      "Epoch 400/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 67.5096 - val_loss: 56.1565\n",
      "Epoch 401/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 69.3062 - val_loss: 56.1754\n",
      "Epoch 402/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 73.7691 - val_loss: 56.1887\n",
      "Epoch 403/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.8566 - val_loss: 56.1777\n",
      "Epoch 404/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.4844 - val_loss: 56.1476\n",
      "Epoch 405/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.2924 - val_loss: 56.1298\n",
      "Epoch 406/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 67.9413 - val_loss: 56.0983\n",
      "Epoch 407/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 64.7839 - val_loss: 56.0269\n",
      "Epoch 408/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 120us/step - loss: 63.3610 - val_loss: 55.9459\n",
      "Epoch 409/1000\n",
      "317/317 [==============================] - 0s 119us/step - loss: 67.4730 - val_loss: 55.8815\n",
      "Epoch 410/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 63.7801 - val_loss: 55.8633\n",
      "Epoch 411/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 62.7250 - val_loss: 55.8263\n",
      "Epoch 412/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 67.3233 - val_loss: 55.8321\n",
      "Epoch 413/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 67.5752 - val_loss: 55.8184\n",
      "Epoch 414/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.0218 - val_loss: 55.7950\n",
      "Epoch 415/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 66.2629 - val_loss: 55.8000\n",
      "Epoch 416/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.5653 - val_loss: 55.7367\n",
      "Epoch 417/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 64.6350 - val_loss: 55.6864\n",
      "Epoch 418/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.0834 - val_loss: 55.6592\n",
      "Epoch 419/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 72.0632 - val_loss: 55.7354\n",
      "Epoch 420/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 70.9307 - val_loss: 55.7974\n",
      "Epoch 421/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.2851 - val_loss: 55.7837\n",
      "Epoch 422/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 68.0079 - val_loss: 55.7475\n",
      "Epoch 423/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.1889 - val_loss: 55.7182\n",
      "Epoch 424/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.0600 - val_loss: 55.7027\n",
      "Epoch 425/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 62.3866 - val_loss: 55.6974\n",
      "Epoch 426/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 65.0139 - val_loss: 55.6425\n",
      "Epoch 427/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 70.2732 - val_loss: 55.6548\n",
      "Epoch 428/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.2906 - val_loss: 55.6645\n",
      "Epoch 429/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 61.9988 - val_loss: 55.5934\n",
      "Epoch 430/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.6302 - val_loss: 55.4935\n",
      "Epoch 431/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4329 - val_loss: 55.4145\n",
      "Epoch 432/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.7593 - val_loss: 55.3389\n",
      "Epoch 433/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.6893 - val_loss: 55.2780\n",
      "Epoch 434/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.5709 - val_loss: 55.2599\n",
      "Epoch 435/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.0228 - val_loss: 55.2033\n",
      "Epoch 436/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.3316 - val_loss: 55.1922\n",
      "Epoch 437/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.2845 - val_loss: 55.1862\n",
      "Epoch 438/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 64.5013 - val_loss: 55.1722\n",
      "Epoch 439/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 68.9566 - val_loss: 55.1509\n",
      "Epoch 440/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.5888 - val_loss: 55.1350\n",
      "Epoch 441/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 67.1938 - val_loss: 55.0922\n",
      "Epoch 442/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.9466 - val_loss: 55.0240\n",
      "Epoch 443/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.0131 - val_loss: 55.0050\n",
      "Epoch 444/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.9111 - val_loss: 55.0177\n",
      "Epoch 445/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 68.7698 - val_loss: 55.0010\n",
      "Epoch 446/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.1641 - val_loss: 54.9984\n",
      "Epoch 447/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.5582 - val_loss: 54.9932\n",
      "Epoch 448/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 65.0447 - val_loss: 55.0145\n",
      "Epoch 449/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 71.6658 - val_loss: 55.0490\n",
      "Epoch 450/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 68.5497 - val_loss: 55.0757\n",
      "Epoch 451/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.3797 - val_loss: 55.0891\n",
      "Epoch 452/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 67.2962 - val_loss: 55.0939\n",
      "Epoch 453/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 65.6153 - val_loss: 55.0948\n",
      "Epoch 454/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 65.9242 - val_loss: 55.1360\n",
      "Epoch 455/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.1075 - val_loss: 55.1394\n",
      "Epoch 456/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.6993 - val_loss: 55.1131\n",
      "Epoch 457/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 69.0146 - val_loss: 55.0996\n",
      "Epoch 458/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 68.9921 - val_loss: 55.0751\n",
      "Epoch 459/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 62.4184 - val_loss: 55.0604\n",
      "Epoch 460/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.5454 - val_loss: 55.0733\n",
      "Epoch 461/1000\n",
      "317/317 [==============================] - 0s 112us/step - loss: 63.9211 - val_loss: 55.0661\n",
      "Epoch 462/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.9072 - val_loss: 54.9949\n",
      "Epoch 463/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 61.8053 - val_loss: 54.9258\n",
      "Epoch 464/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 69.1157 - val_loss: 54.8904\n",
      "Epoch 465/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 66.0806 - val_loss: 54.8839\n",
      "Epoch 466/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 65.0268 - val_loss: 54.8970\n",
      "Epoch 467/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 72.1753 - val_loss: 54.9791\n",
      "Epoch 468/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 69.2939 - val_loss: 55.0379\n",
      "Epoch 469/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 63.6493 - val_loss: 55.0269\n",
      "Epoch 470/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 72.3348 - val_loss: 55.0175\n",
      "Epoch 471/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 63.8573 - val_loss: 55.0379\n",
      "Epoch 472/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 64.3882 - val_loss: 54.9859\n",
      "Epoch 473/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 67.3784 - val_loss: 54.9265\n",
      "Epoch 474/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.5388 - val_loss: 54.8465\n",
      "Epoch 475/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 66.4215 - val_loss: 54.7563\n",
      "Epoch 476/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 66.6490 - val_loss: 54.6869\n",
      "Epoch 477/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.3094 - val_loss: 54.6318\n",
      "Epoch 478/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.0082 - val_loss: 54.5569\n",
      "Epoch 479/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 64.4915 - val_loss: 54.5016\n",
      "Epoch 480/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 72.0488 - val_loss: 54.4894\n",
      "Epoch 481/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 67.0049 - val_loss: 54.4983\n",
      "Epoch 482/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.6192 - val_loss: 54.4832\n",
      "Epoch 483/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 71.1392 - val_loss: 54.5039\n",
      "Epoch 484/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 98us/step - loss: 65.4168 - val_loss: 54.5096\n",
      "Epoch 485/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.4724 - val_loss: 54.5038\n",
      "Epoch 486/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.9358 - val_loss: 54.4949\n",
      "Epoch 487/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 70.3149 - val_loss: 54.4795\n",
      "Epoch 488/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 66.7263 - val_loss: 54.4685\n",
      "Epoch 489/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 67.7062 - val_loss: 54.4199\n",
      "Epoch 490/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.6343 - val_loss: 54.4001\n",
      "Epoch 491/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 63.8862 - val_loss: 54.3535\n",
      "Epoch 492/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 64.9895 - val_loss: 54.3131\n",
      "Epoch 493/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 64.5042 - val_loss: 54.2749\n",
      "Epoch 494/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 68.3848 - val_loss: 54.2681\n",
      "Epoch 495/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 65.2513 - val_loss: 54.2596\n",
      "Epoch 496/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 64.9360 - val_loss: 54.2366\n",
      "Epoch 497/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.9219 - val_loss: 54.2078\n",
      "Epoch 498/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.5933 - val_loss: 54.1972\n",
      "Epoch 499/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.4266 - val_loss: 54.2082\n",
      "Epoch 500/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.9812 - val_loss: 54.2312\n",
      "Epoch 501/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 65.7913 - val_loss: 54.2194\n",
      "Epoch 502/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.9808 - val_loss: 54.2063\n",
      "Epoch 503/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 66.1416 - val_loss: 54.2157\n",
      "Epoch 504/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 66.7102 - val_loss: 54.2229\n",
      "Epoch 505/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 74.2086 - val_loss: 54.2501\n",
      "Epoch 506/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 70.1356 - val_loss: 54.2765\n",
      "Epoch 507/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 69.4182 - val_loss: 54.3324\n",
      "Epoch 508/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.1259 - val_loss: 54.3478\n",
      "Epoch 509/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.5345 - val_loss: 54.3314\n",
      "Epoch 510/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 62.4262 - val_loss: 54.3340\n",
      "Epoch 511/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.5540 - val_loss: 54.3104\n",
      "Epoch 512/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4699 - val_loss: 54.2444\n",
      "Epoch 513/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.7491 - val_loss: 54.2110\n",
      "Epoch 514/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.7014 - val_loss: 54.2230\n",
      "Epoch 515/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4375 - val_loss: 54.1741\n",
      "Epoch 516/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.0542 - val_loss: 54.1312\n",
      "Epoch 517/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 67.6226 - val_loss: 54.1142\n",
      "Epoch 518/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.9463 - val_loss: 54.1172\n",
      "Epoch 519/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 67.9707 - val_loss: 54.0946\n",
      "Epoch 520/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 67.4456 - val_loss: 54.1043\n",
      "Epoch 521/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 68.1197 - val_loss: 54.1039\n",
      "Epoch 522/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.6065 - val_loss: 54.1228\n",
      "Epoch 523/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 70.8752 - val_loss: 54.1813\n",
      "Epoch 524/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 68.8288 - val_loss: 54.2078\n",
      "Epoch 525/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4033 - val_loss: 54.1980\n",
      "Epoch 526/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 66.0168 - val_loss: 54.2202\n",
      "Epoch 527/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 66.6739 - val_loss: 54.2356\n",
      "Epoch 528/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.0726 - val_loss: 54.2225\n",
      "Epoch 529/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4112 - val_loss: 54.1851\n",
      "Epoch 530/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 66.4084 - val_loss: 54.1820\n",
      "Epoch 531/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.1423 - val_loss: 54.1812\n",
      "Epoch 532/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.7582 - val_loss: 54.1822\n",
      "Epoch 533/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 61.0914 - val_loss: 54.1413\n",
      "Epoch 534/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 64.1963 - val_loss: 54.0974\n",
      "Epoch 535/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 61.6449 - val_loss: 54.0632\n",
      "Epoch 536/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.5685 - val_loss: 54.0390\n",
      "Epoch 537/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 67.2563 - val_loss: 54.0290\n",
      "Epoch 538/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.5593 - val_loss: 53.9984\n",
      "Epoch 539/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.8675 - val_loss: 53.9834\n",
      "Epoch 540/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 63.4521 - val_loss: 53.9757\n",
      "Epoch 541/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.5569 - val_loss: 53.9698\n",
      "Epoch 542/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.3736 - val_loss: 53.9708\n",
      "Epoch 543/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.1192 - val_loss: 53.9512\n",
      "Epoch 544/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.0406 - val_loss: 53.9296\n",
      "Epoch 545/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.0929 - val_loss: 53.9213\n",
      "Epoch 546/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.4957 - val_loss: 53.9001\n",
      "Epoch 547/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.1102 - val_loss: 53.8753\n",
      "Epoch 548/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 59.3752 - val_loss: 53.8432\n",
      "Epoch 549/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 63.1985 - val_loss: 53.8125\n",
      "Epoch 550/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 74.0910 - val_loss: 53.8143\n",
      "Epoch 551/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 66.6098 - val_loss: 53.8252\n",
      "Epoch 552/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 67.1574 - val_loss: 53.8526\n",
      "Epoch 553/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.5959 - val_loss: 53.8550\n",
      "Epoch 554/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.7807 - val_loss: 53.8593\n",
      "Epoch 555/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 62.2050 - val_loss: 53.8610\n",
      "Epoch 556/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.0802 - val_loss: 53.8617\n",
      "Epoch 557/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.0124 - val_loss: 53.8632\n",
      "Epoch 558/1000\n",
      "317/317 [==============================] - 0s 111us/step - loss: 64.1161 - val_loss: 53.8564\n",
      "Epoch 559/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 66.6919 - val_loss: 53.8451\n",
      "Epoch 560/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 101us/step - loss: 66.6392 - val_loss: 53.8196\n",
      "Epoch 561/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.4086 - val_loss: 53.8096\n",
      "Epoch 562/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.1259 - val_loss: 53.8071\n",
      "Epoch 563/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 66.8573 - val_loss: 53.8177\n",
      "Epoch 564/1000\n",
      "317/317 [==============================] - 0s 111us/step - loss: 66.7674 - val_loss: 53.8218\n",
      "Epoch 565/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.0727 - val_loss: 53.8054\n",
      "Epoch 566/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.1899 - val_loss: 53.7994\n",
      "Epoch 567/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.5375 - val_loss: 53.7934\n",
      "Epoch 568/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 63.9443 - val_loss: 53.8026\n",
      "Epoch 569/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.2721 - val_loss: 53.8067\n",
      "Epoch 570/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4066 - val_loss: 53.8242\n",
      "Epoch 571/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.4297 - val_loss: 53.8156\n",
      "Epoch 572/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.6116 - val_loss: 53.8134\n",
      "Epoch 573/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.8841 - val_loss: 53.8060\n",
      "Epoch 574/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.1216 - val_loss: 53.8041\n",
      "Epoch 575/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 58.5602 - val_loss: 53.7741\n",
      "Epoch 576/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 63.8710 - val_loss: 53.7339\n",
      "Epoch 577/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.1822 - val_loss: 53.7224\n",
      "Epoch 578/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 68.3947 - val_loss: 53.7143\n",
      "Epoch 579/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 63.8658 - val_loss: 53.7089\n",
      "Epoch 580/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.6611 - val_loss: 53.7042\n",
      "Epoch 581/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.8543 - val_loss: 53.6929\n",
      "Epoch 582/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.7773 - val_loss: 53.6804\n",
      "Epoch 583/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.1171 - val_loss: 53.6724\n",
      "Epoch 584/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 59.4997 - val_loss: 53.6546\n",
      "Epoch 585/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.9949 - val_loss: 53.6481\n",
      "Epoch 586/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 63.1915 - val_loss: 53.6411\n",
      "Epoch 587/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 60.3422 - val_loss: 53.6359\n",
      "Epoch 588/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.0694 - val_loss: 53.6296\n",
      "Epoch 589/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.0489 - val_loss: 53.6243\n",
      "Epoch 590/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.2480 - val_loss: 53.6182\n",
      "Epoch 591/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 69.6863 - val_loss: 53.6201\n",
      "Epoch 592/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 60.5276 - val_loss: 53.6207\n",
      "Epoch 593/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 65.1856 - val_loss: 53.6168\n",
      "Epoch 594/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 61.3500 - val_loss: 53.6100\n",
      "Epoch 595/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 63.5771 - val_loss: 53.5902\n",
      "Epoch 596/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 62.5649 - val_loss: 53.5884\n",
      "Epoch 597/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.5155 - val_loss: 53.6017\n",
      "Epoch 598/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 61.4645 - val_loss: 53.6128\n",
      "Epoch 599/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 61.3796 - val_loss: 53.6111\n",
      "Epoch 600/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 62.9465 - val_loss: 53.6034\n",
      "Epoch 601/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.4494 - val_loss: 53.5893\n",
      "Epoch 602/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 65.9822 - val_loss: 53.5775\n",
      "Epoch 603/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.9998 - val_loss: 53.5797\n",
      "Epoch 604/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.0789 - val_loss: 53.5802\n",
      "Epoch 605/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 62.2566 - val_loss: 53.5792\n",
      "Epoch 606/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 59.3681 - val_loss: 53.5727\n",
      "Epoch 607/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.5214 - val_loss: 53.5683\n",
      "Epoch 608/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 66.4953 - val_loss: 53.5692\n",
      "Epoch 609/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.2883 - val_loss: 53.5629\n",
      "Epoch 610/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.4948 - val_loss: 53.5506\n",
      "Epoch 611/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 62.6304 - val_loss: 53.5423\n",
      "Epoch 612/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.6880 - val_loss: 53.5326\n",
      "Epoch 613/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.8166 - val_loss: 53.5250\n",
      "Epoch 614/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.1216 - val_loss: 53.5230\n",
      "Epoch 615/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.5130 - val_loss: 53.5136\n",
      "Epoch 616/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 60.0981 - val_loss: 53.5159\n",
      "Epoch 617/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.0023 - val_loss: 53.5138\n",
      "Epoch 618/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 64.7882 - val_loss: 53.5052\n",
      "Epoch 619/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.1944 - val_loss: 53.4859\n",
      "Epoch 620/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 63.7676 - val_loss: 53.4856\n",
      "Epoch 621/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 60.9480 - val_loss: 53.4812\n",
      "Epoch 622/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.9717 - val_loss: 53.4821\n",
      "Epoch 623/1000\n",
      "317/317 [==============================] - 0s 119us/step - loss: 61.5153 - val_loss: 53.4933\n",
      "Epoch 624/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.9637 - val_loss: 53.4974\n",
      "Epoch 625/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.8414 - val_loss: 53.5008\n",
      "Epoch 626/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.2128 - val_loss: 53.4919\n",
      "Epoch 627/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 63.8665 - val_loss: 53.4697\n",
      "Epoch 628/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.5304 - val_loss: 53.4567\n",
      "Epoch 629/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 62.6605 - val_loss: 53.4631\n",
      "Epoch 630/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.4046 - val_loss: 53.4552\n",
      "Epoch 631/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 67.6870 - val_loss: 53.4437\n",
      "Epoch 632/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.9734 - val_loss: 53.4329\n",
      "Epoch 633/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.3299 - val_loss: 53.4279\n",
      "Epoch 634/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.2604 - val_loss: 53.4294\n",
      "Epoch 635/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.1373 - val_loss: 53.4345\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 101us/step - loss: 61.6654 - val_loss: 53.4364\n",
      "Epoch 637/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.7603 - val_loss: 53.4476\n",
      "Epoch 638/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.8156 - val_loss: 53.4430\n",
      "Epoch 639/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 64.6441 - val_loss: 53.4394\n",
      "Epoch 640/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.6089 - val_loss: 53.4367\n",
      "Epoch 641/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 64.1690 - val_loss: 53.4296\n",
      "Epoch 642/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.7606 - val_loss: 53.4170\n",
      "Epoch 643/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.6055 - val_loss: 53.4187\n",
      "Epoch 644/1000\n",
      "317/317 [==============================] - 0s 89us/step - loss: 65.2210 - val_loss: 53.4178\n",
      "Epoch 645/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 65.1813 - val_loss: 53.4194\n",
      "Epoch 646/1000\n",
      "317/317 [==============================] - 0s 90us/step - loss: 64.3854 - val_loss: 53.4277\n",
      "Epoch 647/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.4828 - val_loss: 53.4308\n",
      "Epoch 648/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 60.0632 - val_loss: 53.4358\n",
      "Epoch 649/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.4723 - val_loss: 53.4470\n",
      "Epoch 650/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.9460 - val_loss: 53.4550\n",
      "Epoch 651/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 66.6378 - val_loss: 53.4404\n",
      "Epoch 652/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 63.2909 - val_loss: 53.4378\n",
      "Epoch 653/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 64.4147 - val_loss: 53.4396\n",
      "Epoch 654/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.8118 - val_loss: 53.4372\n",
      "Epoch 655/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 66.0386 - val_loss: 53.4266\n",
      "Epoch 656/1000\n",
      "317/317 [==============================] - 0s 112us/step - loss: 66.1352 - val_loss: 53.4119\n",
      "Epoch 657/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.4300 - val_loss: 53.4049\n",
      "Epoch 658/1000\n",
      "317/317 [==============================] - 0s 109us/step - loss: 66.6144 - val_loss: 53.4028\n",
      "Epoch 659/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.6735 - val_loss: 53.4005\n",
      "Epoch 660/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.0037 - val_loss: 53.4042\n",
      "Epoch 661/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 61.3702 - val_loss: 53.4143\n",
      "Epoch 662/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.0559 - val_loss: 53.4319\n",
      "Epoch 663/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.7757 - val_loss: 53.4513\n",
      "Epoch 664/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.1971 - val_loss: 53.4566\n",
      "Epoch 665/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 59.2201 - val_loss: 53.4684\n",
      "Epoch 666/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.5322 - val_loss: 53.4755\n",
      "Epoch 667/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 59.8795 - val_loss: 53.4675\n",
      "Epoch 668/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 66.4725 - val_loss: 53.4607\n",
      "Epoch 669/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.4216 - val_loss: 53.4564\n",
      "Epoch 670/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.4125 - val_loss: 53.4568\n",
      "Epoch 671/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 66.7099 - val_loss: 53.4473\n",
      "Epoch 672/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 59.1843 - val_loss: 53.4364\n",
      "Epoch 673/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.0779 - val_loss: 53.4345\n",
      "Epoch 674/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.3856 - val_loss: 53.4324\n",
      "Epoch 675/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 63.9863 - val_loss: 53.4291\n",
      "Epoch 676/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.3998 - val_loss: 53.4299\n",
      "Epoch 677/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 62.9454 - val_loss: 53.4250\n",
      "Epoch 678/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.1125 - val_loss: 53.4236\n",
      "Epoch 679/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 59.1303 - val_loss: 53.4226\n",
      "Epoch 680/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 66.8588 - val_loss: 53.4232\n",
      "Epoch 681/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.5487 - val_loss: 53.4355\n",
      "Epoch 682/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 60.7839 - val_loss: 53.4444\n",
      "Epoch 683/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 65.3984 - val_loss: 53.4282\n",
      "Epoch 684/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 59.8974 - val_loss: 53.4176\n",
      "Epoch 685/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.7550 - val_loss: 53.4264\n",
      "Epoch 686/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.8347 - val_loss: 53.4350\n",
      "Epoch 687/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.8062 - val_loss: 53.4185\n",
      "Epoch 688/1000\n",
      "317/317 [==============================] - 0s 111us/step - loss: 60.8829 - val_loss: 53.4092\n",
      "Epoch 689/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.5858 - val_loss: 53.4039\n",
      "Epoch 690/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 62.0602 - val_loss: 53.4008\n",
      "Epoch 691/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 65.5680 - val_loss: 53.3952\n",
      "Epoch 692/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.2876 - val_loss: 53.3920\n",
      "Epoch 693/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.9150 - val_loss: 53.3847\n",
      "Epoch 694/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.9871 - val_loss: 53.3868\n",
      "Epoch 695/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.3984 - val_loss: 53.3824\n",
      "Epoch 696/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.2281 - val_loss: 53.3946\n",
      "Epoch 697/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.4359 - val_loss: 53.4026\n",
      "Epoch 698/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.1450 - val_loss: 53.3967\n",
      "Epoch 699/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.4771 - val_loss: 53.3986\n",
      "Epoch 700/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.1803 - val_loss: 53.3959\n",
      "Epoch 701/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.7340 - val_loss: 53.3831\n",
      "Epoch 702/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 60.4051 - val_loss: 53.3631\n",
      "Epoch 703/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 63.7152 - val_loss: 53.3428\n",
      "Epoch 704/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.9514 - val_loss: 53.3241\n",
      "Epoch 705/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 60.5093 - val_loss: 53.3231\n",
      "Epoch 706/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.6445 - val_loss: 53.3184\n",
      "Epoch 707/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.7051 - val_loss: 53.3149\n",
      "Epoch 708/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 58.7443 - val_loss: 53.3299\n",
      "Epoch 709/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 59.6474 - val_loss: 53.3414\n",
      "Epoch 710/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 66.9696 - val_loss: 53.3472\n",
      "Epoch 711/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 64.6119 - val_loss: 53.3433\n",
      "Epoch 712/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 95us/step - loss: 64.0847 - val_loss: 53.3400\n",
      "Epoch 713/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 60.5413 - val_loss: 53.3305\n",
      "Epoch 714/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 60.1924 - val_loss: 53.3285\n",
      "Epoch 715/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 59.4137 - val_loss: 53.3193\n",
      "Epoch 716/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.0394 - val_loss: 53.3201\n",
      "Epoch 717/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.7392 - val_loss: 53.3087\n",
      "Epoch 718/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.3582 - val_loss: 53.2942\n",
      "Epoch 719/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.4828 - val_loss: 53.2862\n",
      "Epoch 720/1000\n",
      "317/317 [==============================] - 0s 108us/step - loss: 63.8720 - val_loss: 53.2869\n",
      "Epoch 721/1000\n",
      "317/317 [==============================] - 0s 117us/step - loss: 60.6538 - val_loss: 53.2847\n",
      "Epoch 722/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 63.2855 - val_loss: 53.2846\n",
      "Epoch 723/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.6799 - val_loss: 53.3029\n",
      "Epoch 724/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 63.3930 - val_loss: 53.3134\n",
      "Epoch 725/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.3425 - val_loss: 53.3049\n",
      "Epoch 726/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.6981 - val_loss: 53.3064\n",
      "Epoch 727/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.3517 - val_loss: 53.3057\n",
      "Epoch 728/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.1351 - val_loss: 53.3097\n",
      "Epoch 729/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 61.5072 - val_loss: 53.3164\n",
      "Epoch 730/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 65.4437 - val_loss: 53.3132\n",
      "Epoch 731/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.4912 - val_loss: 53.3005\n",
      "Epoch 732/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 67.2589 - val_loss: 53.2834\n",
      "Epoch 733/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.8408 - val_loss: 53.2636\n",
      "Epoch 734/1000\n",
      "317/317 [==============================] - 0s 93us/step - loss: 58.7125 - val_loss: 53.2630\n",
      "Epoch 735/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 63.9931 - val_loss: 53.2709\n",
      "Epoch 736/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.1197 - val_loss: 53.2878\n",
      "Epoch 737/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 61.4259 - val_loss: 53.3009\n",
      "Epoch 738/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.6246 - val_loss: 53.2986\n",
      "Epoch 739/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.9803 - val_loss: 53.2949\n",
      "Epoch 740/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.5944 - val_loss: 53.2960\n",
      "Epoch 741/1000\n",
      "317/317 [==============================] - ETA: 0s - loss: 53.38 - 0s 98us/step - loss: 60.9563 - val_loss: 53.2907\n",
      "Epoch 742/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.8751 - val_loss: 53.2794\n",
      "Epoch 743/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.4820 - val_loss: 53.2632\n",
      "Epoch 744/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 63.5868 - val_loss: 53.2568\n",
      "Epoch 745/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.9138 - val_loss: 53.2457\n",
      "Epoch 746/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.7321 - val_loss: 53.2366\n",
      "Epoch 747/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.8196 - val_loss: 53.2325\n",
      "Epoch 748/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 67.6050 - val_loss: 53.2282\n",
      "Epoch 749/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.5912 - val_loss: 53.2248\n",
      "Epoch 750/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 60.3327 - val_loss: 53.2251\n",
      "Epoch 751/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.3291 - val_loss: 53.2325\n",
      "Epoch 752/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 63.6833 - val_loss: 53.2402\n",
      "Epoch 753/1000\n",
      "317/317 [==============================] - 0s 114us/step - loss: 64.1816 - val_loss: 53.2405\n",
      "Epoch 754/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 63.0380 - val_loss: 53.2393\n",
      "Epoch 755/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 58.6448 - val_loss: 53.2399\n",
      "Epoch 756/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 70.1137 - val_loss: 53.2396\n",
      "Epoch 757/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 58.8669 - val_loss: 53.2408\n",
      "Epoch 758/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.5174 - val_loss: 53.2494\n",
      "Epoch 759/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 64.3179 - val_loss: 53.2510\n",
      "Epoch 760/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.6248 - val_loss: 53.2473\n",
      "Epoch 761/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 64.9547 - val_loss: 53.2432\n",
      "Epoch 762/1000\n",
      "317/317 [==============================] - 0s 103us/step - loss: 61.1712 - val_loss: 53.2458\n",
      "Epoch 763/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.2817 - val_loss: 53.2463\n",
      "Epoch 764/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 61.7351 - val_loss: 53.2582\n",
      "Epoch 765/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 60.5172 - val_loss: 53.2769\n",
      "Epoch 766/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 57.8754 - val_loss: 53.3127\n",
      "Epoch 767/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 62.0984 - val_loss: 53.3569\n",
      "Epoch 768/1000\n",
      "317/317 [==============================] - 0s 100us/step - loss: 61.7416 - val_loss: 53.3942\n",
      "Epoch 769/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 62.5421 - val_loss: 53.4139\n",
      "Epoch 770/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.1349 - val_loss: 53.4350\n",
      "Epoch 771/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 59.0306 - val_loss: 53.4541\n",
      "Epoch 772/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 64.3119 - val_loss: 53.4036\n",
      "Epoch 773/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.2141 - val_loss: 53.3578\n",
      "Epoch 774/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 57.6890 - val_loss: 53.3932\n",
      "Epoch 775/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 60.8037 - val_loss: 53.4335\n",
      "Epoch 776/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 57.4118 - val_loss: 53.4712\n",
      "Epoch 777/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.6937 - val_loss: 53.4510\n",
      "Epoch 778/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 61.2129 - val_loss: 53.4125\n",
      "Epoch 779/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 57.6736 - val_loss: 53.3856\n",
      "Epoch 780/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 62.4184 - val_loss: 53.3613\n",
      "Epoch 781/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 58.5610 - val_loss: 53.3622\n",
      "Epoch 782/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 61.3699 - val_loss: 53.3700\n",
      "Epoch 783/1000\n",
      "317/317 [==============================] - 0s 101us/step - loss: 64.3138 - val_loss: 53.3316\n",
      "Epoch 784/1000\n",
      "317/317 [==============================] - 0s 123us/step - loss: 62.4587 - val_loss: 53.3069\n",
      "Epoch 785/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 59.3641 - val_loss: 53.3026\n",
      "Epoch 786/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 61.3965 - val_loss: 53.3321\n",
      "Epoch 787/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 60.7081 - val_loss: 53.3738\n",
      "Epoch 788/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 95us/step - loss: 58.7059 - val_loss: 53.4050\n",
      "Epoch 789/1000\n",
      "317/317 [==============================] - 0s 104us/step - loss: 63.5708 - val_loss: 53.4662\n",
      "Epoch 790/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 65.6700 - val_loss: 53.4926\n",
      "Epoch 791/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.2308 - val_loss: 53.4720\n",
      "Epoch 792/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 63.3723 - val_loss: 53.4606\n",
      "Epoch 793/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 65.1762 - val_loss: 53.4815\n",
      "Epoch 794/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 62.2483 - val_loss: 53.4848\n",
      "Epoch 795/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 63.8401 - val_loss: 53.4754\n",
      "Epoch 796/1000\n",
      "317/317 [==============================] - 0s 92us/step - loss: 58.9810 - val_loss: 53.4569\n",
      "Epoch 797/1000\n",
      "317/317 [==============================] - 0s 95us/step - loss: 62.4112 - val_loss: 53.4573\n",
      "Epoch 798/1000\n",
      "317/317 [==============================] - 0s 98us/step - loss: 60.0673 - val_loss: 53.4476\n",
      "Epoch 799/1000\n",
      "317/317 [==============================] - 0s 96us/step - loss: 67.1376 - val_loss: 53.4168\n",
      "Epoch 00799: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "reg=None#l1_l2(0.01,0.02)\n",
    "\n",
    "def stackLayers(layerSet):\n",
    "    #print (layerSet)\n",
    "    stack = layerSet[0]\n",
    "    if len(layerSet)>1:\n",
    "        for i in range (0,len(layerSet)-1):\n",
    "            stack=layerSet[i+1](stack)\n",
    "    return (stack)\n",
    "weatherLayers=[]\n",
    "weatherLayers+=[Input((3,))]\n",
    "weatherLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "weatherLayers+=[Dropout(0.5)]\n",
    "weatherLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "weatherLayers+=[Dropout(0.5)]\n",
    "weatherLayers+=[Dense(5, activation='relu',kernel_regularizer=reg)]\n",
    "weatherLayers+=[Dropout(0.5)]\n",
    "weatherLayers+=[Dense(4, activation='relu',kernel_regularizer=reg)]\n",
    "weatherOut=stackLayers(weatherLayers)\n",
    "print (weatherOut)\n",
    "\n",
    "dayLayers=[]\n",
    "dayLayers+=[Input((7,))]\n",
    "dayLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "dayLayers+=[Dropout(0.5)]\n",
    "dayLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "dayLayers+=[Dropout(0.5)]\n",
    "dayLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "dayLayers+=[Dropout(0.5)]\n",
    "dayLayers+=[Dense(5, activation='relu',kernel_regularizer=reg)]\n",
    "dayOut=stackLayers(dayLayers)\n",
    "\n",
    "dateLayers=[]\n",
    "dateLayers+=[Input((1,))]\n",
    "dateLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "dateLayers+=[Dropout(0.5)]\n",
    "dateLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "dateLayers+=[Dropout(0.5)]\n",
    "dateLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "dateLayers+=[Dropout(0.5)]\n",
    "dateLayers+=[Dense(5, activation='relu',kernel_regularizer=reg)]\n",
    "dateOut=stackLayers(dateLayers)\n",
    "\n",
    "mainLayers=[]\n",
    "mainLayers+=[concatenate([weatherOut,dayOut])]\n",
    "mainLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "mainLayers+=[Dropout(0.5)]\n",
    "mainLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "mainLayers+=[Dropout(0.5)]\n",
    "mainLayers+=[Dense(10, activation='relu',kernel_regularizer=reg)]\n",
    "mainLayers+=[Dropout(0.5)]\n",
    "mainLayers+=[Dense(1, activation='linear')]\n",
    "mainOut=stackLayers(mainLayers)\n",
    "\n",
    "model=Model(inputs=[weatherLayers[0],dayLayers[0],dateLayers[0]],outputs=[mainOut])\n",
    "model.compile(loss='mean_absolute_percentage_error',\n",
    "              optimizer=Adam(0.0001))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(patience=50, verbose=1)\n",
    "history = model.fit([weather_x,day_x,date_x], [y],\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n",
    "from math import ceil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 3)\n",
      "36/36 [==============================] - 0s 362us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.090850830078125"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evalSeg=317\n",
    "print (weather_x[evalSeg:].shape)\n",
    "model.evaluate(x=[weather_x[evalSeg:],day_x[evalSeg:],date_x[evalSeg:]],y=[y[evalSeg:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93],\n",
       "       [ 73],\n",
       "       [ 87],\n",
       "       [ 97],\n",
       "       [ 92],\n",
       "       [ 88],\n",
       "       [ 39],\n",
       "       [ 40],\n",
       "       [ 74],\n",
       "       [ 67],\n",
       "       [ 88],\n",
       "       [105],\n",
       "       [150],\n",
       "       [ 94],\n",
       "       [ 74],\n",
       "       [ 95],\n",
       "       [ 83],\n",
       "       [108],\n",
       "       [104],\n",
       "       [109],\n",
       "       [122],\n",
       "       [ 69],\n",
       "       [ 55],\n",
       "       [ 96],\n",
       "       [135],\n",
       "       [119],\n",
       "       [ 97],\n",
       "       [ 88],\n",
       "       [ 61],\n",
       "       [ 61],\n",
       "       [138],\n",
       "       [ 85],\n",
       "       [ 92],\n",
       "       [104],\n",
       "       [ 87],\n",
       "       [ 58],\n",
       "       [ 98],\n",
       "       [ 99],\n",
       "       [154],\n",
       "       [ 78],\n",
       "       [115],\n",
       "       [119],\n",
       "       [132],\n",
       "       [ 98],\n",
       "       [ 89],\n",
       "       [ 92],\n",
       "       [ 81],\n",
       "       [140],\n",
       "       [162],\n",
       "       [147],\n",
       "       [138],\n",
       "       [112],\n",
       "       [ 94],\n",
       "       [155],\n",
       "       [191],\n",
       "       [116],\n",
       "       [ 75],\n",
       "       [ 87],\n",
       "       [ 93],\n",
       "       [106],\n",
       "       [110],\n",
       "       [ 96],\n",
       "       [ 97],\n",
       "       [ 53],\n",
       "       [ 82],\n",
       "       [ 97],\n",
       "       [127],\n",
       "       [128],\n",
       "       [101],\n",
       "       [114],\n",
       "       [ 62],\n",
       "       [ 66],\n",
       "       [ 63],\n",
       "       [ 75],\n",
       "       [107],\n",
       "       [113],\n",
       "       [130],\n",
       "       [ 81],\n",
       "       [100],\n",
       "       [119],\n",
       "       [103],\n",
       "       [ 87],\n",
       "       [149],\n",
       "       [215],\n",
       "       [ 99],\n",
       "       [120],\n",
       "       [ 91],\n",
       "       [156],\n",
       "       [ 96],\n",
       "       [116],\n",
       "       [180],\n",
       "       [113],\n",
       "       [ 61],\n",
       "       [141],\n",
       "       [157],\n",
       "       [ 92],\n",
       "       [106],\n",
       "       [172],\n",
       "       [175],\n",
       "       [177],\n",
       "       [171],\n",
       "       [228],\n",
       "       [277],\n",
       "       [338],\n",
       "       [294],\n",
       "       [146],\n",
       "       [140],\n",
       "       [163],\n",
       "       [103],\n",
       "       [206],\n",
       "       [264],\n",
       "       [130],\n",
       "       [101],\n",
       "       [ 46],\n",
       "       [100],\n",
       "       [217],\n",
       "       [201],\n",
       "       [317],\n",
       "       [212],\n",
       "       [148],\n",
       "       [116],\n",
       "       [146],\n",
       "       [170],\n",
       "       [118],\n",
       "       [222],\n",
       "       [124],\n",
       "       [110],\n",
       "       [ 94],\n",
       "       [157],\n",
       "       [148],\n",
       "       [ 99],\n",
       "       [ 84],\n",
       "       [155],\n",
       "       [159],\n",
       "       [167],\n",
       "       [224],\n",
       "       [177],\n",
       "       [144],\n",
       "       [245],\n",
       "       [158],\n",
       "       [107],\n",
       "       [135],\n",
       "       [107],\n",
       "       [113],\n",
       "       [142],\n",
       "       [298],\n",
       "       [161],\n",
       "       [104],\n",
       "       [143],\n",
       "       [132],\n",
       "       [141],\n",
       "       [191],\n",
       "       [275],\n",
       "       [218],\n",
       "       [130],\n",
       "       [125],\n",
       "       [244],\n",
       "       [219],\n",
       "       [212],\n",
       "       [303],\n",
       "       [157],\n",
       "       [ 39],\n",
       "       [ 73],\n",
       "       [ 84],\n",
       "       [201],\n",
       "       [148],\n",
       "       [156],\n",
       "       [174],\n",
       "       [ 93],\n",
       "       [117],\n",
       "       [198],\n",
       "       [144],\n",
       "       [123],\n",
       "       [188],\n",
       "       [179],\n",
       "       [113],\n",
       "       [117],\n",
       "       [151],\n",
       "       [155],\n",
       "       [147],\n",
       "       [141],\n",
       "       [120],\n",
       "       [116],\n",
       "       [ 89],\n",
       "       [109],\n",
       "       [179],\n",
       "       [205],\n",
       "       [126],\n",
       "       [ 71],\n",
       "       [ 64],\n",
       "       [ 93],\n",
       "       [ 88],\n",
       "       [117],\n",
       "       [191],\n",
       "       [164],\n",
       "       [109],\n",
       "       [103],\n",
       "       [117],\n",
       "       [153],\n",
       "       [134],\n",
       "       [145],\n",
       "       [105],\n",
       "       [126],\n",
       "       [119],\n",
       "       [157],\n",
       "       [164],\n",
       "       [153],\n",
       "       [105],\n",
       "       [142],\n",
       "       [153],\n",
       "       [147],\n",
       "       [158],\n",
       "       [157],\n",
       "       [127],\n",
       "       [220],\n",
       "       [163],\n",
       "       [116],\n",
       "       [ 82],\n",
       "       [166],\n",
       "       [159],\n",
       "       [163],\n",
       "       [164],\n",
       "       [ 86],\n",
       "       [179],\n",
       "       [160],\n",
       "       [140],\n",
       "       [222],\n",
       "       [135],\n",
       "       [151],\n",
       "       [157],\n",
       "       [ 98],\n",
       "       [117],\n",
       "       [130],\n",
       "       [139],\n",
       "       [130],\n",
       "       [185],\n",
       "       [153],\n",
       "       [ 86],\n",
       "       [104],\n",
       "       [ 67],\n",
       "       [110],\n",
       "       [124],\n",
       "       [ 63],\n",
       "       [ 70],\n",
       "       [123],\n",
       "       [ 91],\n",
       "       [101],\n",
       "       [ 52],\n",
       "       [ 78],\n",
       "       [127],\n",
       "       [100],\n",
       "       [ 82],\n",
       "       [ 87],\n",
       "       [ 91],\n",
       "       [ 90],\n",
       "       [ 95],\n",
       "       [175],\n",
       "       [277],\n",
       "       [105],\n",
       "       [119],\n",
       "       [136],\n",
       "       [114],\n",
       "       [129],\n",
       "       [194],\n",
       "       [174],\n",
       "       [110],\n",
       "       [112],\n",
       "       [143],\n",
       "       [131],\n",
       "       [114],\n",
       "       [145],\n",
       "       [116],\n",
       "       [104],\n",
       "       [111],\n",
       "       [141],\n",
       "       [124],\n",
       "       [134],\n",
       "       [177],\n",
       "       [134],\n",
       "       [ 89],\n",
       "       [ 97],\n",
       "       [118],\n",
       "       [ 94],\n",
       "       [ 81],\n",
       "       [117],\n",
       "       [135],\n",
       "       [110],\n",
       "       [ 99],\n",
       "       [118],\n",
       "       [ 94],\n",
       "       [148],\n",
       "       [194],\n",
       "       [191],\n",
       "       [111],\n",
       "       [ 85],\n",
       "       [ 98],\n",
       "       [117],\n",
       "       [ 88],\n",
       "       [132],\n",
       "       [171],\n",
       "       [ 51],\n",
       "       [ 65],\n",
       "       [ 60],\n",
       "       [ 57],\n",
       "       [ 60],\n",
       "       [119],\n",
       "       [ 37],\n",
       "       [ 28],\n",
       "       [ 46],\n",
       "       [ 26],\n",
       "       [ 21],\n",
       "       [ 29],\n",
       "       [ 26],\n",
       "       [ 32],\n",
       "       [ 16],\n",
       "       [ 19],\n",
       "       [ 29],\n",
       "       [ 25],\n",
       "       [ 55],\n",
       "       [ 42],\n",
       "       [ 57],\n",
       "       [ 39],\n",
       "       [ 37],\n",
       "       [ 41],\n",
       "       [ 25],\n",
       "       [  5],\n",
       "       [ 30],\n",
       "       [ 48],\n",
       "       [ 26],\n",
       "       [ 50],\n",
       "       [ 53],\n",
       "       [ 75],\n",
       "       [ 81],\n",
       "       [159],\n",
       "       [ 71],\n",
       "       [ 64],\n",
       "       [ 68],\n",
       "       [ 72],\n",
       "       [ 66],\n",
       "       [ 76],\n",
       "       [ 76],\n",
       "       [ 60],\n",
       "       [ 46],\n",
       "       [ 61],\n",
       "       [ 53],\n",
       "       [ 61],\n",
       "       [ 59],\n",
       "       [ 57],\n",
       "       [ 76],\n",
       "       [ 44],\n",
       "       [ 59],\n",
       "       [ 87],\n",
       "       [106]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
