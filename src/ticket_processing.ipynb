{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from geopy import Nominatim\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from time import sleep\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "geolocator = Nominatim()\n",
    "\n",
    "# used a geocoder to translate street addresses to coordinates\n",
    "def locToCoords(location):\n",
    "    sleep(1.1)\n",
    "    coords = geolocator.geocode(location + \" Charlottesville\")\n",
    "    if coords is not None and coords.longitude is not None:\n",
    "        longitude = coords.longitude\n",
    "        latitude = coords.latitude\n",
    "        return(latitude, longitude)\n",
    "    return(\"Did not process\")\n",
    "\n",
    "# Mall coordinates -  (38.031233, -78.482905) (38.029413, -78.477146)\n",
    "def distToMall(posTuple):\n",
    "    lat = posTuple[0]\n",
    "    long = posTuple[1]\n",
    "    p1 = np.array([38.031233, -78.482905])\n",
    "    p2 = np.array([38.029413, -78.477146])\n",
    "    p3 = np.array([lat, long])\n",
    "    return norm(np.cross(p2 - p1, p1 - p3)) / norm(p2 - p1)\n",
    "\n",
    "# pandas apply didn't want to work with a dataframe\n",
    "# so this was my workaround don't judge pls\n",
    "def dict_to_coords(value):\n",
    "    try:\n",
    "        return locdict[value]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data, normal stuff. Dropping duplicates based on location to reduce number of queries\n",
    "ticket_path = os.path.join('..','data','parking_tickets','Parking_Tickets.csv')\n",
    "data = pd.read_csv(ticket_path, low_memory=0)\n",
    "data = data[data['DateIssued'].str.contains('2017')].sort_values(by=['DateIssued'])\n",
    "no_dup_data = data.drop_duplicates(['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# querying the geocoder and saving the result\n",
    "no_dup_data['Coords'] = no_dup_data[\"Location\"].apply(locToCoords)\n",
    "no_dup_data.to_csv('with_coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn these two columns into a dict so we can apply to the duplicates\n",
    "locdict = no_dup_data.set_index('Location')['Coords'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out values that the geocoder couldn't parse\n",
    "data = data[data['Location'].isin(locdict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the dict to the full list with duplicates\n",
    "data['Coords'] = data['Location'].apply(dict_to_coords)\n",
    "data = data[data['Coords'] != np.nan]\n",
    "# distance squared, clipped at .025, which is right on the mall (getting rid of crazy low values)\n",
    "data['DistMetric'] = data['Coords'].apply(distToMall).apply(lambda x: max(x**2 * 10**5, .025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "data.to_csv('ticket_with_loc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
