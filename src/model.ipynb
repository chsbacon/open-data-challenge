{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_path = os.path.join('..','data','weather','precip_temp.csv')\n",
    "weather_df = pd.read_csv(weather_path)\n",
    "clients_path = os.path.join('..','data','wifi','**','Clients per day.csv')\n",
    "clients_df = pd.concat(map(lambda csv: pd.read_csv(csv, parse_dates=[0]),\n",
    "                           glob.glob(clients_path)), ignore_index=True)\n",
    "sessions_path = os.path.join('..','data','wifi','**','Number of sessions over time.csv')\n",
    "sessions_df = pd.concat(map(lambda csv: pd.read_csv(csv, parse_dates=[0]),\n",
    "                               glob.glob(sessions_path)), ignore_index=True)\n",
    "usage_path = os.path.join('..','data','wifi','**','Usage over time.csv')\n",
    "usage_df = pd.concat(map(lambda csv: pd.read_csv(csv, parse_dates=[0]),\n",
    "                               glob.glob(usage_path)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of the week as a one-hot\n",
    "weekday_labels = []\n",
    "for d in range(7):\n",
    "    label = 'weekday-%i' % d\n",
    "    weekday_labels.append(label)\n",
    "    clients_df[label] = [int(dt.weekday()==d) for dt in clients_df['Time']]\n",
    "    \n",
    "# Put wifi date in the same format as it is in the weather data\n",
    "clients_df['Time'] = [dt.strftime('%Y-%m-%d') for dt in clients_df['Time']]\n",
    "sessions_df['Time'] = [dt.strftime('%Y-%m-%d') for dt in sessions_df['Time']]\n",
    "usage_df['Date'] = [dt.strftime('%Y-%m-%d') for dt in usage_df['Time']]\n",
    "usage_df['Hour'] = [dt.hour for dt in usage_df['Time']]\n",
    "\n",
    "\n",
    "all_data = clients_df.merge(weather_df, left_on='Time', right_on='DATE') \\\n",
    "    .merge(sessions_df, left_on='Time', right_on='Time')\n",
    "\n",
    "# Put 4-hour chunks together into rows by day\n",
    "usage_labels = set()\n",
    "for index, row in usage_df.iterrows():\n",
    "    download_label = 'download-%i' % row['Hour']\n",
    "    all_data.loc[all_data['DATE'] == row['Date'], download_label] \\\n",
    "        = row['Download (B)']\n",
    "    usage_labels.add(download_label)\n",
    "    total_label = 'total-%i' % row['Hour']\n",
    "    all_data.loc[all_data['DATE'] == row['Date'], total_label] \\\n",
    "        = row['Total (B)']\n",
    "    usage_labels.add(total_label)\n",
    "usage_labels = list(usage_labels)\n",
    "\n",
    "# Normalize some inputs using z-scores\n",
    "cols_to_norm = ['TMIN', 'TMAX', 'PRCP']\n",
    "for col in cols_to_norm:\n",
    "    all_data[col] = zscore(all_data[col])\n",
    "\n",
    "# Separate inputs into categories for encoding\n",
    "day_x = all_data[weekday_labels].values\n",
    "weather_x = all_data[['PRCP', 'TMAX', 'TMIN']].values\n",
    "date_x = np.expand_dims(np.arange(0, 353/365, 1/365).astype('float32'), axis=1)\n",
    "\n",
    "y_labels = ['# Clients'] + usage_labels\n",
    "y = all_data[y_labels].values\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "reg = None # l1_l2(0.01,0.02)\n",
    "\n",
    "def stack_layers(layers):\n",
    "    return reduce(lambda stack, e: e(stack), layers)\n",
    "\n",
    "weather_layers = \\\n",
    "  [Input((3,))] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(5, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(4, activation='relu',kernel_regularizer=reg)]\n",
    "\n",
    "weather_out = stack_layers(weather_layers)\n",
    "\n",
    "day_layers = \\\n",
    "  [Input((7,))] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(5, activation='relu',kernel_regularizer=reg)]\n",
    "\n",
    "day_out = stack_layers(day_layers)\n",
    "\n",
    "date_layers = \\\n",
    "  [Input((1,))] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(5, activation='relu',kernel_regularizer=reg)]\n",
    "\n",
    "date_out = stack_layers(date_layers)\n",
    "\n",
    "main_layers = \\\n",
    "  [concatenate([weather_out, day_out, date_out])] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(10, activation='relu',kernel_regularizer=reg)] \\\n",
    "+ [Dropout(0.5)] \\\n",
    "+ [Dense(13, activation='linear')]\n",
    "\n",
    "main_out = stack_layers(main_layers)\n",
    "\n",
    "model = Model(inputs=[weather_layers[0], day_layers[0], date_layers[0]], outputs=[main_out])\n",
    "model.compile(loss='mean_absolute_percentage_error',\n",
    "              optimizer=Adam(0.0001))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(patience=50, verbose=1)\n",
    "history = model.fit([weather_x,day_x,date_x], [y],\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalSeg=317\n",
    "print (weather_x[evalSeg:].shape)\n",
    "model.evaluate(x=[weather_x[evalSeg:],day_x[evalSeg:],date_x[evalSeg:]],y=[y[evalSeg:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
